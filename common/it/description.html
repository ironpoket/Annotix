<p>
  Partecipando a questo progetto potrete sperimentare direttamente l’area grigia
  tra la libertà di espressione e il discorso d’odio online. Siete pronti?
  <br /><br />
  L’Hate speech è la punta dell’iceberg di un linguaggio virale costellato di
  elementi discriminatori più o meno espliciti che a volte si diffondono
  mascherati da battuta, difficili da identificare come “Hate speech”.
  <br /><br />
  La tecnologia dell’IA si sta sviluppando a velocità esponenziale e il rischio
  che sia un catalizzatore della diffusione di bias e stereotipi è un rischio
  concreto. <br />
  Da qui, la necessità di uno strumento in grado di apprendere all’IA come
  individuare il linguaggio discriminatorio e, eventualmente, evitarlo.
  <br /><br />
  Questi sono i presupposti alla base dello sviluppo di AnnotIx, un nuovo editor
  che ha come obiettivo quello di rendere l’intelligenza artificiale più
  sensibile al linguaggio discriminatorio confrontando il sistema di
  categorizzazione algoritmi con i processi di categorizzazione umana.
  <br /><br />
  Può un algoritmo cogliere le varie forme di discorso d’odio con la stessa
  sensibilità di un essere umano? E’ quello che stiamo cercando di scoprire e
  per questo la tua partecipazione a questa mostra è preziosa.
  <br /><br />
  Testando AnnotIx, riconoscendo frasi che possono essere percepite come
  discriminatorie o non inclusive nei confronti di alcune categorie, come ad
  esempio il genere, l'orientamento sessuale, l'etnia e la religione, ci
  aiuterai a mettere a punto il nostro editor.
  <br /><br />
  Partecipando, contribuirai ad un progetto di ricerca che intende indagare
  l’area grigia tra free speech e hate speech e aiuterai ad individuare i semi
  dell'odio che si annidano nel linguaggio del web. <br />
  Un passo verso un mondo digitale più rispettoso delle diversità.
</p>
